{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP-based AAN (AAN-A) models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### All the test is based on torch-1.2.0 and torchtext-0.6.0\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torchtext import data\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.nn import functional as F\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data loader based on torchtext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator_feature(source_file, target_file, BATCH_SIZE=128):\n",
    "    '''\n",
    "    source_file: the source domain dataset in datasets/amazon_reivew/\n",
    "    target file: the source domain dataset in datasets/amazon_reivew/\n",
    "    '''\n",
    "    TEXT = data.Field(dtype = torch.float,sequential=False, batch_first = True,use_vocab=False)\n",
    "    LABEL = data.LabelField(dtype = torch.long,use_vocab=False)\n",
    "\n",
    "    fields = {'text': ('text', TEXT), 'label': ('label', LABEL)}\n",
    "\n",
    "    train_data = data.TabularDataset.splits(\n",
    "                            path = 'datasets'+os.sep+\"amazon_review\",\n",
    "                            train = source_file,\n",
    "                            format = 'json',\n",
    "                            fields = fields\n",
    "    )\n",
    "    test_data = data.TabularDataset.splits(\n",
    "                            path = 'datasets'+os.sep+\"amazon_review\",\n",
    "                            train = target_file,\n",
    "                            format = 'json',\n",
    "                            fields = fields\n",
    "    )\n",
    "\n",
    "    train_data = train_data[0]\n",
    "    test_data = test_data[0]\n",
    "    ## A very small  target labeled data (50 samples) is used to validate the model. You can set it to zeros. \n",
    "    test_data, valid_data = test_data.split(random_state = random.seed(SEED), split_ratio=0.90)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    source_iterator, target_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "        (train_data, test_data, valid_data), \n",
    "        batch_size = BATCH_SIZE, \n",
    "        sort=False,\n",
    "        shuffle = True,\n",
    "        # repeat=True,\n",
    "        device = device)\n",
    "\n",
    "    return source_iterator, target_iterator, valid_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize AAN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.models import  AANMLP\n",
    "from model.criterion import MMD_loss\n",
    "\n",
    "aan_version='AAN-A'  ## or 'AAN'\n",
    "\n",
    "dataset = ['books_400.mat.json','dvd_400.mat.json','elec_400.mat.json','kitchen_400.mat.json']\n",
    "\n",
    "source_file =dataset[2]\n",
    "target_file = dataset[1]\n",
    "\n",
    "source_iterator, target_iterator, valid_iterator = get_iterator_feature(source_file, target_file, BATCH_SIZE=128)\n",
    "\n",
    "INPUT_DIM = 400\n",
    "LATENT_DIM = 100\n",
    "OUTPUT_DIM = 2\n",
    "DROPOUT = 0.25\n",
    "MU = 0.1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = AANMLP(INPUT_DIM,LATENT_DIM,OUTPUT_DIM, DROPOUT, aan_version)\n",
    "\n",
    "if aan_version == 'AAN':\n",
    "    optimizer_task = optim.Adam(model.parameters())\n",
    "else:\n",
    "    optimizer_task = optim.Adam([{'params':model.extractor.parameters()},{'params':model.predictor.parameters()}])\n",
    "    optimizer_kernel = optim.Adam([{'params':model.mmd_linear.parameters()},{'params':model.cmmd_linear.parameters()}])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "mmd_loss = MMD_loss(kernel_type='mmd', kernel_mul=2.0, kernel_num=5)\n",
    "cmmd_loss = MMD_loss(kernel_type='cmmd', kernel_mul=2.0, kernel_num=5,eplison=0.00001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training AAN (AAN-A) models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch: 01 | Epoch Time: 0m 2s | Best Epoch:01\n\tTrain Loss: 0.986|Valid Acc: 0.540\nEpoch: 02 | Epoch Time: 0m 0s | Best Epoch:01\n\tTrain Loss: 0.968|Valid Acc: 0.540\nEpoch: 03 | Epoch Time: 0m 1s | Best Epoch:03\n\tTrain Loss: 0.967|Valid Acc: 0.580\nEpoch: 04 | Epoch Time: 0m 1s | Best Epoch:04\n\tTrain Loss: 0.986|Valid Acc: 0.710\nEpoch: 05 | Epoch Time: 0m 1s | Best Epoch:04\n\tTrain Loss: 0.956|Valid Acc: 0.485\nEpoch: 06 | Epoch Time: 0m 0s | Best Epoch:06\n\tTrain Loss: 1.002|Valid Acc: 0.575\nEpoch: 07 | Epoch Time: 0m 1s | Best Epoch:07\n\tTrain Loss: 0.947|Valid Acc: 0.655\nEpoch: 08 | Epoch Time: 0m 1s | Best Epoch:08\n\tTrain Loss: 0.963|Valid Acc: 0.630\nEpoch: 09 | Epoch Time: 0m 0s | Best Epoch:09\n\tTrain Loss: 0.968|Valid Acc: 0.710\nEpoch: 10 | Epoch Time: 0m 1s | Best Epoch:10\n\tTrain Loss: 0.910|Valid Acc: 0.730\nEpoch: 11 | Epoch Time: 0m 0s | Best Epoch:11\n\tTrain Loss: 0.908|Valid Acc: 0.785\nEpoch: 12 | Epoch Time: 0m 0s | Best Epoch:12\n\tTrain Loss: 0.805|Valid Acc: 0.780\nEpoch: 13 | Epoch Time: 0m 0s | Best Epoch:13\n\tTrain Loss: 0.731|Valid Acc: 0.810\nEpoch: 14 | Epoch Time: 0m 0s | Best Epoch:13\n\tTrain Loss: 0.626|Valid Acc: 0.760\nEpoch: 15 | Epoch Time: 0m 0s | Best Epoch:15\n\tTrain Loss: 0.596|Valid Acc: 0.760\nEpoch: 16 | Epoch Time: 0m 0s | Best Epoch:16\n\tTrain Loss: 0.577|Valid Acc: 0.815\nEpoch: 17 | Epoch Time: 0m 0s | Best Epoch:17\n\tTrain Loss: 0.615|Valid Acc: 0.815\nEpoch: 18 | Epoch Time: 0m 1s | Best Epoch:17\n\tTrain Loss: 0.572|Valid Acc: 0.780\nEpoch: 19 | Epoch Time: 0m 1s | Best Epoch:17\n\tTrain Loss: 0.574|Valid Acc: 0.795\nEpoch: 20 | Epoch Time: 0m 1s | Best Epoch:17\n\tTrain Loss: 0.573|Valid Acc: 0.775\nEpoch: 21 | Epoch Time: 0m 1s | Best Epoch:17\n\tTrain Loss: 0.532|Valid Acc: 0.775\nEpoch: 22 | Epoch Time: 0m 0s | Best Epoch:17\n\tTrain Loss: 0.556|Valid Acc: 0.785\nEpoch: 23 | Epoch Time: 0m 0s | Best Epoch:17\n\tTrain Loss: 0.583|Valid Acc: 0.765\nEpoch: 24 | Epoch Time: 0m 0s | Best Epoch:17\n\tTrain Loss: 0.585|Valid Acc: 0.795\nEpoch: 25 | Epoch Time: 0m 0s | Best Epoch:17\n\tTrain Loss: 0.516|Valid Acc: 0.745\nEpoch: 26 | Epoch Time: 0m 0s | Best Epoch:17\n\tTrain Loss: 0.526|Valid Acc: 0.740\nEpoch: 27 | Epoch Time: 0m 1s | Best Epoch:17\n\tTrain Loss: 0.555|Valid Acc: 0.730\nEpoch: 28 | Epoch Time: 0m 0s | Best Epoch:17\n\tTrain Loss: 0.501|Valid Acc: 0.775\nEpoch: 29 | Epoch Time: 0m 0s | Best Epoch:17\n\tTrain Loss: 0.490|Valid Acc: 0.730\nEpoch: 30 | Epoch Time: 0m 0s | Best Epoch:17\n\tTrain Loss: 0.484|Valid Acc: 0.730\n"
    }
   ],
   "source": [
    "from model.tools import train_adverisal,  train_normal, evaluate, epoch_time\n",
    "\n",
    "N_EPOCHS = 30\n",
    "best_loss = 100.0\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    if aan_version == 'AAN-A':\n",
    "        train_loss = train_adverisal(model,source_iterator,target_iterator,optimizer_task,optimizer_kernel,criterion,mmd_loss,cmmd_loss)\n",
    "    else:\n",
    "        train_loss = train_normal(model,source_iterator,target_iterator,optimizer_task,criterion,mmd_loss,cmmd_loss,MU)\n",
    "\n",
    "\n",
    "    eval_acc,eval_loss = evaluate(model, valid_iterator, criterion)\n",
    "    if eval_loss < best_loss:\n",
    "        best_loss = eval_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(),'mmd-task-model.pt')\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s | Best Epoch:{best_epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}|Valid Acc: {eval_acc:.3f}') \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test AAN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "from elec_400.mat.json to dvd_400.mat.json, acc is 0.787104\n"
    }
   ],
   "source": [
    "from model.tools import evaluate\n",
    "\n",
    "### test the model.\n",
    "model.load_state_dict(torch.load('mmd-task-model.pt'))\n",
    "eval_acc,eval_loss  = evaluate(model,target_iterator,criterion)\n",
    "print('from %s to %s, acc is %f'%(source_file,target_file, eval_acc))"
   ]
  }
 ]
}